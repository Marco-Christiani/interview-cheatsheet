{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Math/Statistics","text":""},{"location":"#mathstatistics","title":"Math/Statistics","text":""},{"location":"#probability-vs-likelihood","title":"Probability vs. Likelihood","text":"<ul> <li>Probability: During the testing phase, given a learned model, we     determine the probability of observing the outcome</li> <li>Likelihood: During training, given some outcome we determine the     likelihood of observing theta that maximizes the probability of that     outcome (MLE).</li> </ul>"},{"location":"#bayes-theorem","title":"Bayes Theorem","text":"<ul> <li>Revise prediction using new evidence</li> <li>Naive Bayes Classifier: Generative Classification model</li> </ul>"},{"location":"#linear-transformation","title":"Linear Transformation","text":"<ul> <li>Rotation (produced by shearing) and scaling</li> </ul> \\[     f(\\alpha x + \\beta y)=\\alpha f(x)+\\beta f(y) \\]"},{"location":"#affine-transformation","title":"Affine Transformation","text":"<p>AKA a linear transformation plus translation </p> \\[     f(\\alpha x + (1-\\alpha)y)=\\alpha f(x)+(1-\\alpha)f(y) \\] \\[     f(x)=\\vec{a}^Tx+\\vec{b} \\] <p>Properties Perserved:</p> <ol> <li>Collinearity between points: points on same line (collinear points)     remain on same line after transformation</li> <li>Parallelism: Parallel lines remain parallel</li> <li>Convexity of sets: Furthermore, extreme points of original set map     to extreme points of transformed set</li> <li>Length Ratios of Parallel lines</li> <li>Barycenters of weighted collections of points. Aka center of mass. ?</li> </ol>"},{"location":"codepuzzles/","title":"Code Puzzles","text":""},{"location":"codepuzzles/#reverse-a-linked-list","title":"Reverse a Linked List","text":"<pre><code>Curr=head\nwhile curr:\nNext = curr.next\nCurr.next = prev\nPrev = curr\nCurr = next\nreturn prev (new head)\n</code></pre>"},{"location":"codepuzzles/#longest-palindrome","title":"Longest Palindrome","text":"<pre><code>def longest_palindrome(s: str):\nif not s:\nreturn \"\"\nlongest = \"\"\nfor i in range(len(s)):\n# odd case, like \"aba\"\ntmp = helper(s, i, i)\nif len(tmp) &gt; len(longest):\n# update result\nlongest = tmp\n# even case, like \"abba\"\ntmp = helper(s, i, i+1)\nif len(tmp) &gt; len(longest):\nlongest = tmp\nreturn longest\ndef helper(s: str, l: int, r: int):\nwhile l &gt;= 0 and r &lt; len(s) and s[l] == s[r]:\nl -= 1 # decrement the left\nr += 1 # increment the right\nreturn s[l+1:r]\n</code></pre>"},{"location":"codepuzzles/#bfs-not-recursive","title":"BFS (not recursive)","text":"<pre><code># Visit adjacent unvisited vertex. \n# - Mark it as visited. Display it. Insert it in a queue.\n# If no adjacent vertex, pop vertex off queue\n# Repeat Rule 1 and Rule 2 until the queue is empty. \ndef bfs(graph, current_node):\nvisited = []\nqueue = [current_node]\nwhile queue:\ns = queue.pop(0)\nprint(s)\nfor neighbor in graph[s]:\nif neighbor not in visited:\nvisited.append(neighbor)\nqueue.append(neighbor)\nbfs(graph, 'A')\n</code></pre>"},{"location":"codepuzzles/#dfs-not-recursive","title":"DFS (not recursive)","text":"<pre><code># add unvisited nodes to stack\ndef dfs(graph, start_vertex):\nvisited = set()\ntraversal = []\nstack = [start_vertex]\nwhile stack:\nvertex = stack.pop()\nif vertex not in visited:\nvisited.add(vertex)\ntraversal.append(vertex)\nstack.extend(reversed(graph[vertex])) # add in same order as visited\nreturn traversal\n</code></pre>"},{"location":"codepuzzles/#check-if-binary-trees-are-equal","title":"Check if binary trees are equal:","text":"<pre><code>def are_identical(root1, root2):\nif root1 == None and root2 == None:\nreturn True\nif root1 != None and root2 != None:\nreturn (root1.data == root2.data and\nare_identical(root1.left, root2.left) and\nare_identical(root1.right, root2.right))\nreturn False\n</code></pre>"},{"location":"fin/","title":"Finance Fundamentals","text":""},{"location":"fin/#balancesheet","title":"Balancesheet","text":"<p>Liquidity, capital assets, credit metrics, liquidity ratios, leverage, ROA (return on assets), ROW (return on equity)</p> <p>Shows a company's...</p> <ol> <li>Assets</li> <li>Liabilities</li> <li>Shareholders' equity (what it owns, owes, is worth)</li> </ol>"},{"location":"fin/#income-statement","title":"Income Statement","text":"<p>Growth rates, margins, profitability</p> <p>Shows a company's...</p> <ol> <li>Revenue</li> <li>Expenses</li> <li>Net Income</li> </ol>"},{"location":"fin/#cash-flow-statement","title":"Cash Flow Statement","text":"<p>Short/long term cash flow profile, needs to raise money or return capital to shareholders</p> <p>Shows a company's cash inflows/outlflows from...</p> <ol> <li>Operation</li> <li>Investments</li> <li>Financing</li> </ol>"},{"location":"fin/#finance-formulas","title":"Finance Formulas","text":"<ul> <li>Revenue = Volume x Price</li> <li>Cost = Fixed Cost + Variable Cost</li> <li>Profit = Revenue - Cost</li> <li>Profitability or Profit Margin = Profit/Revenue</li> <li>ROI = Annual Profit / Principal Investment</li> <li>Breakeven or Payback Period = Principal / Annual Profit</li> <li>ROE = Profits / Shareholder Equity</li> <li>ROA = Profits / Total Assets</li> <li>WACC: Weighted Average Cost of Capital<ul> <li>Blended cost of capital across all sources (common/preferred shares, debt)</li> <li>(% debt vs total capital) x (1-effective tax rate)+(% equity vs capital) x (required return on equity) check this</li> </ul> </li> </ul>"},{"location":"fin/#questions","title":"Questions","text":""},{"location":"fin/#what-is-cheaper-debt-or-equity","title":"What is cheaper: debt or equity?","text":"<ul> <li>Debt: backed by collateral and paid off before equity</li> <li>Debt is more liquid ?</li> </ul>"},{"location":"fin/#what-is-the-best-financial-statement-to-measure-a-companys-health","title":"What is the best financial statement to measure a company's health?","text":"<p>Cash is king. Cash Flow Statement shows how much cash company is actually generating</p> <p>Arguments for other statements:</p> <ul> <li>Balance Sheet: assets are true driver of cash flow</li> <li>Income Statement: Earning power and profitability on an accural basis</li> </ul>"},{"location":"ml/","title":"General","text":""},{"location":"ml/#discriminative-model","title":"Discriminative Model","text":"<ul> <li>learn decision boundaries between classes</li> <li>SVM, Logistic Regression, Decision Trees</li> <li>Not great w outliers</li> <li>Maximizes conditional likelihood, given model parameters<ul> <li>\\(L(\\theta)=\\max{P(y | x;\\ \\theta)}\\)</li> </ul> </li> </ul>"},{"location":"ml/#generative-model","title":"Generative Model","text":"<ul> <li>Distribution of classes themselves</li> <li>Na\u00efve Bayes, Discriminant Analysis (LDA, GDA)</li> <li>Better with outliers</li> <li>Maximizes joint likelihood: the joint probability given model     parameters<ul> <li>\\(L(\\theta)=\\max{P(x, y;\\ \\theta)}\\)</li> </ul> </li> </ul>"},{"location":"ml/#cross-validation","title":"Cross Validation","text":"<ul> <li>Typically use k-fold validation: i.e. leave one out cross validation</li> <li>Roll forward Cross Validation: used with Time Series Data</li> </ul>"},{"location":"ml/#tree-pruning","title":"Tree Pruning","text":"<ul> <li>Mitigate Overfitting</li> </ul>"},{"location":"ml/#cost-effective-pruning","title":"Cost Effective Pruning:","text":"<ul> <li>Remove a subtree (replacing with a leaf node)</li> <li>if resulting tree does not have a significant decrease in     performance (delta formula) then keep the new pruned tree and     repeat.</li> </ul>"},{"location":"ml/#ensemble-learning","title":"Ensemble learning","text":"<ul> <li>Boosting, Bagging, Random Forest</li> <li>Aggregation mitigates overfitting of a class</li> </ul>"},{"location":"ml/#bagging","title":"Bagging","text":"<ul> <li>Train several models and vote to produce output.</li> </ul>"},{"location":"ml/#boosting","title":"Boosting","text":"<ul> <li>Use a model to improve performance where another model is weakest.     (i.e. model the error)</li> </ul>"},{"location":"ml/#fourier-transform","title":"Fourier Transform","text":"<ul> <li>Decompose functions into its constituent parts.</li> </ul>"},{"location":"ml/#logistic-regression","title":"Logistic Regression","text":"<ul> <li>Regression for classification.</li> <li>Linear model produces logits, softmax(logits) produces prediction</li> </ul>"},{"location":"ml/#model-evaluation","title":"Model Evaluation","text":""},{"location":"ml/#roc","title":"ROC","text":"<ul> <li>Receiver Operator Characteristic</li> <li>Graphs Sensitivity vs Specificity (OR Precision)</li> <li>i.e. True Positive vs True Negative Rates</li> </ul>"},{"location":"ml/#accuracy","title":"Accuracy","text":"<p>True predictions/Number points</p>"},{"location":"ml/#precision","title":"Precision","text":"<p>\\(\\text{precision}=TP/(TP+FP)\\)</p> <ul> <li>How many of our positive predictions were right?</li> <li>Positive Prediction Accuracy for the label</li> <li>Proportion of positive results that were correctly classified</li> <li>\\(\\text{precision}=\\text{true\\_pos}/(\\text{true\\_pos} + \\text{true\\_neg})\\)</li> <li>Good if we have an imbalance such as way more negatives than     positives (not in eq)</li> </ul>"},{"location":"ml/#sensitivityrecall","title":"Sensitivity/Recall","text":"<p>\\begin{align}       \\text{sensitivity}&amp;=TP/(TP+FN)\\       &amp;=\\text{true_pos}/(\\text{true_pos} + \\text{false_neg})   \\end{align}</p> <ul> <li>Calcualtes the True Positive Rate of the label.</li> </ul>"},{"location":"ml/#specificity","title":"Specificity","text":"\\[ \\text{specificity}=\\text{TN}/(\\text{TN} + \\text{FP}) \\]"},{"location":"ml/#auc","title":"AUC","text":"<ul> <li>Area Under the Curve</li> <li>Used to compare ROC curves</li> <li>More AUC=better</li> </ul>"},{"location":"ml/#neural-networks","title":"Neural Networks","text":""},{"location":"ml/#rnn","title":"RNN","text":"<ul> <li>Handle sequential data (unlike feedforward nn).</li> <li>Sentiment analysis, text mining, image captioning, time series     problems</li> </ul>"},{"location":"ml/#cnns","title":"CNNs","text":"<ul> <li>Image matrix, filter matrix</li> <li>Slide filter matrix over the image acompute the dot product to get     convolved feature matrix.</li> <li>CNN better than Dense NN for Images: Because less params (no     overfit), more interpretable (can look at weights), CNNs can learn     simple-to-complex patterns (learn complex patterns by learning     several simple patterns)</li> </ul>"},{"location":"ml/#gans","title":"GANs","text":"<ul> <li>Use a Generator and Discriminator (to build an accurate     Discriminator model)</li> </ul>"},{"location":"ml/#activation-functions","title":"Activation Functions","text":"<ol> <li>Softmax<ul> <li>Scales input to (0,1). Output layers</li> </ul> </li> <li>ReLU<ul> <li>Clips input at 0, only non-negative outputs.</li> <li>Produces \"rectified feature map.\" Hidden layers</li> </ul> </li> <li>Swish<ul> <li>Variant of ReLU developed at google, better at some DL tasks</li> </ul> </li> </ol>"},{"location":"ml/#pooling","title":"Pooling","text":"<ul> <li>Pooling is a down-sampling operation that reduces the dimensionality     of the feature map</li> </ul>"},{"location":"ml/#computation-graph","title":"Computation Graph","text":"<ul> <li>Nodes are operations, Edges are tensors/data</li> </ul>"},{"location":"ml/#batch-gradient-vs-stochastic-gradient-descent","title":"Batch Gradient vs Stochastic Gradient Descent","text":""},{"location":"ml/#autoencoder","title":"Autoencoder","text":"<ul> <li>3 Layer model that tries to reconstruct its input using a hidden layer of fewer dimensions to create a latent space representation.</li> <li>In its most basic form, uses dimensionality reduction to perform filtering (i.e. noise).</li> </ul> <p>Regularized Autoencoders: Classification (include Sparse, Denoising, Contractive)</p> <p>Variational Autoencoders: Generative models</p>"},{"location":"ml/#uses","title":"Uses","text":"<ul> <li>Extract features and hidden patterns</li> <li>Dimensionality reduction</li> <li>Denoise images</li> <li>Convert black and w hite images into colored images.</li> </ul>"},{"location":"ml/#transfer-learning","title":"Transfer Learning","text":"<ul> <li>Models: VGG-16, BERT, GPT-3, Inception, Xception</li> </ul>"},{"location":"ml/#vanishing-gradients","title":"Vanishing Gradients","text":"<ul> <li>Use ReLU instead of tanh (try different activation function)</li> <li>Try Xavier initialization (takes into account number of inputs and     outputs).</li> </ul>"},{"location":"ml/#ann-hyperparameters","title":"ANN Hyperparameters","text":"<ol> <li>Batch size: size of input data</li> <li>Epochs: number of times training data is visible to the neural     network to train.</li> <li>Momentum: Dampen/attenuate oscillations in gradient descent. If     the weights matrix is ill conditioned, this helps convergence speed     up a bit.</li> <li>Learning rate: Represents the time required for the network to     update the parameters and learn.</li> </ol>"},{"location":"ml/#dealing-with-datasets","title":"Dealing with Datasets","text":""},{"location":"ml/#imbalanced-datasets","title":"Imbalanced Datasets","text":"<ul> <li>Random Under-sampling: Lots of data in smaller class</li> <li>Random Over-sampling: Not lots of data in smaller class</li> </ul>"},{"location":"ml/#missing-data","title":"Missing Data:","text":"<ul> <li>Imputation (i.e. 0), add a new category for categorical (I.e.     \"other\"), interpolation</li> </ul>"},{"location":"ml/#outliers","title":"Outliers","text":"<ul> <li>*Analyze without and without outliers</li> <li>Trimming: Remove outliers</li> <li>Winsorizing: Ceil/Floor to a max/min non-outlier value</li> </ul>"},{"location":"ml/#smote","title":"SMOTE","text":"<ul> <li>Synthetic Monetary Oversampling*</li> <li>Synthesize new data with minor noise added to existing sample rather     than exact copies</li> </ul>"},{"location":"quant/","title":"Quant","text":""},{"location":"quant/#black-scholes","title":"Black-Scholes","text":"<ul> <li>Originally to valuate European call options</li> <li>American equivalents: Bjerksund-Stendland model, binomial, trinomial     models</li> <li> <p>Uses 5 Factors:</p> <ol> <li>Volatility</li> <li>Price of underlying asset</li> <li>Strike price</li> <li>Time to expiration</li> <li>Risk free interest rate</li> </ol> </li> <li> <p>Black-Scholes Asumptions</p> <ul> <li>Price follows a random walk approximately Geometric brownian     motion with constant drift and volatility (i.e. log(variance) is     constant)</li> <li>No dividends over life of option</li> <li>Movements are random, market is random</li> <li>No transaction costs</li> <li>RFR and volatility are constant (not a strong assumption for     volatility, since that is influenced by supply/demand)</li> <li>Returns are log normal</li> <li>Option is European (can only be exercised at expiration)</li> </ul> </li> </ul>"},{"location":"quant/#greeks","title":"Greeks","text":"<ol> <li> <p>Delta</p> <p>First derivative with respect to price. Rate of change of equilibrium price (aka BS price) with respect to asset price.</p> </li> <li> <p>Gamma</p> <p>Second derivative with respect to price.</p> </li> <li> <p>Theta</p> <p>First derivative with respect to time-to-maturity. Rate of change of equilibrium price with respect to time-to-maturity.</p> </li> <li> <p>Vega</p> <p>Rate of change of equilibrium price with respect to asset volatility.</p> </li> <li> <p>Rho</p> <p>Rate of change of equilibrium price with respect to RF interest rate.</p> </li> </ol>"},{"location":"quant/#pay-off-diagrams","title":"Pay Off Diagrams","text":"<ul> <li>Plot of Underlying Price vs. P&amp;L</li> <li>3 Key Points:<ol> <li>Maximum Loss</li> <li>Maximum Gain</li> <li>Break-even Point</li> </ol> </li> </ul>"},{"location":"quant/#call-options","title":"Call Options","text":"<ul> <li>Break-even: K + P (where K is strike price and P is cost of     option)</li> <li>5 reasons to buy a call option<ol> <li>Bet on upside move with minimal cost (lot of a exposure for     little cost)</li> <li>Unlimited Upside</li> <li>Limited Downside: Can only lose what you paid for the option</li> <li>Increase in Volatility: Option is priced based on its     volatility, so all we need is an increase in volatility to     increase the value of our option</li> <li>Hedge Short Position: Unlimited upside offsets risk of short as     shorts have unlimited downside </li> </ol> </li> </ul>"},{"location":"quant/#call-spread","title":"Call-Spread","text":"<ul> <li>Max Value: difference in strike prices. \\(v_{max} = K_2 - K_1\\)<ul> <li>Where \\(K_2=Sold\\) and \\(K_1=bought\\) strike prices</li> </ul> </li> <li>Max Loss: \\(\\text{max_loss} = \\text{max_value} -P_{cs}\\)<ul> <li>Max value - Price of call-spread</li> </ul> </li> </ul>"},{"location":"quant/#put-call-parity","title":"Put-Call Parity","text":"<ul> <li>Represents an arbitrage opportunity</li> <li>\\(\\text{call_price}+\\text{present_value_discounted} = \\text{put_price} + \\text{spot_price}\\)<ul> <li>(where present value is discounted from the value at RFR)</li> </ul> </li> </ul>"},{"location":"quant/#questions","title":"Questions","text":"<ul> <li>What factors in production could cause a backtested strategy to     perform different than expected?<ul> <li>Slippage, transaction costs, systemic risk, outside events that     cannot be modeled such as state of global     economy/climate/legislation/etc</li> </ul> </li> </ul>"},{"location":"wordprobs/","title":"Word Problems","text":"<ul> <li>Given a random number generator which provides a random real value     between 0 to 1, how can you estimate the value of pi?<ul> <li>Monte Carlo integration (unit circle inside a square, ratio of     points in circle versus points outside)</li> </ul> </li> <li>Find the minimum number of socks I need to take out from a box of     red and black socks to ensure that I have k pairs of socks.<ul> <li>Use Pigeon Hole Principle<ol> <li>Pick up N socks (one of each color)</li> <li>Next sock forms a pair</li> </ol> </li> <li>Answer: 2k+N-1</li> <li>Note: When coding ensure to check if K&gt;total~pairs~ in list     (pairs+=arr[i]/2)</li> </ul> </li> <li> <p>Can you minimize piecewise linear function without adding     auxiliary variables?</p> <ul> <li>See this     lecture</li> <li>Firstly: is the function convex</li> <li> <p>Convex piecewise-linear (piecewise-affine is a more accurate     term) can be expressed as:</p> \\[f(x)=\\max _{i=1, \\ldots, m}\\left(a_{i}^{T} x+b_{i}\\right)\\] </li> <li> <p>Problem becomes: \\(\\min f(x)\\)</p> </li> <li>Therefore minimize each:<ul> <li>\\(\\min t\\) subject to \\(a_{i}^{T} x+b_{i} \\le t\\) for \\(i=1,..,m\\)</li> <li>Basically: no</li> </ul> </li> </ul> </li> </ul>"}]}